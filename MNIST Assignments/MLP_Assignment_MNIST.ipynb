{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP Assignment MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Fccqg4Y0hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf;\n",
        "import numpy as np;\n",
        "from tensorflow import keras;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcJcmxfZZqGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist=tf.keras.datasets.mnist;\n",
        "(xt_train,yt_train),(xt_test,yt_test)=mnist.load_data();\n",
        "batch_size=1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxPxWpLpfr_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot(arr):\n",
        "  targets = np.array(arr).reshape(-1)\n",
        "  return np.eye(10)[targets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsDMpUshfKV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=np.reshape(xt_train,(xt_train.shape[0],784))\n",
        "y_train=onehot(yt_train)\n",
        "\n",
        "x_test=np.reshape(xt_test,(xt_test.shape[0],784))\n",
        "y_test=onehot(yt_test)\n",
        "\n",
        "X=tf.placeholder('float')\n",
        "Y=tf.placeholder('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg5b0hHAZvzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn1=512;\n",
        "nn2=256;\n",
        "nn3=128;\n",
        "ol=10;\n",
        "\n",
        "hl1={\n",
        "    'weights':tf.Variable(tf.random_normal([784,nn1]),dtype=tf.float32),\n",
        "    'bias':tf.Variable(tf.random_normal([1,nn1]),dtype=tf.float32),\n",
        "}\n",
        "\n",
        "hl2={\n",
        "    'weights':tf.Variable(tf.random_normal([nn1,nn2]),dtype=tf.float32),\n",
        "    'bias':tf.Variable(tf.random_normal([1,nn2]),dtype=tf.float32),\n",
        "}\n",
        "\n",
        "hl3={\n",
        "    'weights':tf.Variable(tf.random_normal([nn2,nn3]),dtype=tf.float32),\n",
        "    'bias':tf.Variable(tf.random_normal([1,nn3]),dtype=tf.float32),\n",
        "}\n",
        "\n",
        "outl={\n",
        "    'weights':tf.Variable(tf.random_normal([nn3,ol]),dtype=tf.float32),\n",
        "    'bias':tf.Variable(tf.random_normal([1,ol]),dtype=tf.float32),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LETAnHJSaAFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forwardprop(X):\n",
        "  l1=tf.sigmoid(tf.matmul(X,hl1['weights'])+hl1['bias']);\n",
        "  l2=tf.sigmoid(tf.matmul(l1,hl2['weights'])+hl2['bias']);\n",
        "  l3=tf.sigmoid(tf.matmul(l2,hl3['weights'])+hl3['bias']);\n",
        "  output=tf.matmul(l3,outl['weights'])+outl['bias'];\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT1Yj6Bwhd8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_nn(X,Y):\n",
        "  predictions=forwardprop(X)\n",
        "  \n",
        "  cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions,labels=Y))\n",
        "  \n",
        "  optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
        "  \n",
        "  max_epochs=200\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    init=tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    #epochs\n",
        "    for i in range(0,200):\n",
        "      batches=int(x_train.shape[0]/batch_size)\n",
        "      #batches\n",
        "      epoch_loss=0\n",
        "      for j in range(0,batches):\n",
        "        \n",
        "        x=x_train[j*batch_size:(j+1)*batch_size]\n",
        "        y=y_train[j*batch_size:(j+1)*batch_size]\n",
        "        \n",
        "        _,c=sess.run([optimizer,cost],feed_dict={X:x,Y:y})\n",
        "        epoch_loss+=c\n",
        "      if i%10==0:\n",
        "        print('Epoch Loss ',c,' for epoch ',i)\n",
        "    \n",
        "    p1=tf.argmax(predictions,1)\n",
        "    y1=tf.argmax(Y,1)\n",
        "    correctness=tf.equal(p1,y1)\n",
        "    accuracy=tf.reduce_mean(tf.cast(correctness,'float'))\n",
        "    \n",
        "    acc,pr1,ye1=sess.run([accuracy,p1,y1],feed_dict={X:x_test,Y:y_test})\n",
        "    print(\"Accuracy: \",acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcJl3hVWhrDI",
        "colab_type": "code",
        "outputId": "fcc0cb65-9f9f-49c4-da71-5f108c96cb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "train_nn(X,Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-bc87d695c047>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Epoch Loss  2.7103374  for epoch  0\n",
            "Epoch Loss  0.47744727  for epoch  10\n",
            "Epoch Loss  0.3159118  for epoch  20\n",
            "Epoch Loss  0.22184122  for epoch  30\n",
            "Epoch Loss  0.17427658  for epoch  40\n",
            "Epoch Loss  0.14071478  for epoch  50\n",
            "Epoch Loss  0.14094676  for epoch  60\n",
            "Epoch Loss  0.12914358  for epoch  70\n",
            "Epoch Loss  0.09462278  for epoch  80\n",
            "Epoch Loss  0.084816754  for epoch  90\n",
            "Epoch Loss  0.08123881  for epoch  100\n",
            "Epoch Loss  0.06495729  for epoch  110\n",
            "Epoch Loss  0.06201241  for epoch  120\n",
            "Epoch Loss  0.063296944  for epoch  130\n",
            "Epoch Loss  0.04925996  for epoch  140\n",
            "Epoch Loss  0.05245992  for epoch  150\n",
            "Epoch Loss  0.039838783  for epoch  160\n",
            "Epoch Loss  0.04182678  for epoch  170\n",
            "Epoch Loss  0.038034193  for epoch  180\n",
            "Epoch Loss  0.023567135  for epoch  190\n",
            "Accuracy:  0.9484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfwX2V1Onl6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}